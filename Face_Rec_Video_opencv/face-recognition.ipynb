{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install face_recognition\n!pip install opencv","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:14:16.139836Z","iopub.execute_input":"2022-08-14T00:14:16.140206Z","iopub.status.idle":"2022-08-14T00:14:53.635426Z","shell.execute_reply.started":"2022-08-14T00:14:16.140109Z","shell.execute_reply":"2022-08-14T00:14:53.634275Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall opencv-python-headless -y \n!pip install opencv-python --upgrade","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:15:58.482312Z","iopub.execute_input":"2022-08-14T00:15:58.482689Z","iopub.status.idle":"2022-08-14T00:16:15.583314Z","shell.execute_reply.started":"2022-08-14T00:15:58.482660Z","shell.execute_reply":"2022-08-14T00:16:15.582125Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### AUTOMATICALLY FIND ALL THE FACES IN AN IMAGE","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport face_recognition\n\n# Load the jpg file into a numpy array\nimage = face_recognition.load_image_file(\"../input/face-recognition-package/examples/biden.jpg\")\n\n# Find all the faces in the image using the default HOG-based model.\n# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n# See also: find_faces_in_picture_cnn.py\nface_locations = face_recognition.face_locations(image)\n\nprint(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n\nfor face_location in face_locations:\n\n    # Print the location of each face in this image\n    top, right, bottom, left = face_location\n    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n\n    # You can access the actual face itself like this:\n    face_image = image[top:bottom, left:right]\n    pil_image = Image.fromarray(face_image)\n    pil_image.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:25:09.956521Z","iopub.execute_input":"2022-08-14T00:25:09.957238Z","iopub.status.idle":"2022-08-14T00:25:11.544669Z","shell.execute_reply.started":"2022-08-14T00:25:09.957203Z","shell.execute_reply":"2022-08-14T00:25:11.542884Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### AUTOMATICALLY LOCATE THE FACIAL FEATURES OF A PERSON IN AN IMAGE","metadata":{}},{"cell_type":"code","source":"from PIL import Image, ImageDraw\nimport face_recognition\n\n# Load the jpg file into a numpy array\nimage = face_recognition.load_image_file(\"../input/face-recognition-package/examples/two_people.jpg\")\n\n# Find all facial features in all the faces in the image\nface_landmarks_list = face_recognition.face_landmarks(image)\n\nprint(\"I found {} face(s) in this photograph.\".format(len(face_landmarks_list)))\n\n# Create a PIL imagedraw object so we can draw on the picture\npil_image = Image.fromarray(image)\nd = ImageDraw.Draw(pil_image)\n\nfor face_landmarks in face_landmarks_list:\n\n    # Print the location of each facial feature in this image\n    for facial_feature in face_landmarks.keys():\n        print(\"The {} in this face has the following points: {}\".format(facial_feature, face_landmarks[facial_feature]))\n\n    # Let's trace out each facial feature in the image with a line!\n    for facial_feature in face_landmarks.keys():\n        d.line(face_landmarks[facial_feature], width=5)\n\n# Show the picture\npil_image.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:25:53.440347Z","iopub.execute_input":"2022-08-14T00:25:53.440741Z","iopub.status.idle":"2022-08-14T00:25:54.138295Z","shell.execute_reply.started":"2022-08-14T00:25:53.440710Z","shell.execute_reply":"2022-08-14T00:25:54.135658Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### RECOGNIZE FACES IN IMAGES AND IDENTIFY WHO THEY ARE\n","metadata":{}},{"cell_type":"code","source":"import face_recognition\n\n# Load the jpg files into numpy arrays\nbiden_image = face_recognition.load_image_file(\"../input/face-recognition-package/examples/biden.jpg\")\nobama_image = face_recognition.load_image_file(\"../input/face-recognition-package/examples/obama.jpg\")\nunknown_image = face_recognition.load_image_file(\"../input/face-recognition-package/examples/obama2.jpg\")\n\n# Get the face encodings for each face in each image file\n# Since there could be more than one face in each image, it returns a list of encodings.\n# But since I know each image only has one face, I only care about the first encoding in each image, so I grab index 0.\ntry:\n    biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n    obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n    unknown_face_encoding = face_recognition.face_encodings(unknown_image)[0]\nexcept IndexError:\n    print(\"I wasn't able to locate any faces in at least one of the images. Check the image files. Aborting...\")\n    quit()\n\nknown_faces = [\n    biden_face_encoding,\n    obama_face_encoding\n]\n\n# results is an array of True/False telling if the unknown face matched anyone in the known_faces array\nresults = face_recognition.compare_faces(known_faces, biden_face_encoding)\nprint(\"Is the unknown face a picture of Biden? {}\".format(results[0]))\nprint(\"Is the unknown face a picture of Obama? {}\".format(results[1]))\nprint(\"Is the unknown face a new person that we've never seen before? {}\".format(not True in results))","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:27:00.306584Z","iopub.execute_input":"2022-08-14T00:27:00.307001Z","iopub.status.idle":"2022-08-14T00:27:03.506119Z","shell.execute_reply.started":"2022-08-14T00:27:00.306968Z","shell.execute_reply":"2022-08-14T00:27:03.505005Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### FACE RECOGNITION FROM VIDEO FILE","metadata":{}},{"cell_type":"code","source":"import face_recognition\nimport cv2\n\n# This is a demo of running face recognition on a video file and saving the results to a new video file.\n#\n# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n\n# Open the input movie file\ninput_movie = cv2.VideoCapture(\"../input/face-recognition-package/examples/hamilton_clip.mp4\")\nlength = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n\n# Create an output movie file (make sure resolution/frame rate matches input video!)\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\noutput_movie = cv2.VideoWriter('output.avi', fourcc, 29.97, (640, 360))\n\n# Load some sample pictures and learn how to recognize them.\nlmm_image = face_recognition.load_image_file(\"../input/face-recognition-package/examples/lin-manuel-miranda.png\")\nlmm_face_encoding = face_recognition.face_encodings(lmm_image)[0]\n\nal_image = face_recognition.load_image_file(\"../input/face-recognition-package/examples/alex-lacamoire.png\")\nal_face_encoding = face_recognition.face_encodings(al_image)[0]\n\nknown_faces = [\n    lmm_face_encoding,\n    al_face_encoding\n]\n\n# Initialize some variables\nface_locations = []\nface_encodings = []\nface_names = []\nframe_number = 0\n\nwhile True:\n    # Grab a single frame of video\n    ret, frame = input_movie.read()\n    frame_number += 1\n\n    # Quit when the input video file ends\n    if not ret:\n        break\n\n    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n    rgb_frame = frame[:, :, ::-1]\n\n    # Find all the faces and face encodings in the current frame of video\n    face_locations = face_recognition.face_locations(rgb_frame)\n    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n\n    face_names = []\n    for face_encoding in face_encodings:\n        # See if the face is a match for the known face(s)\n        match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n\n        # If you had more than 2 faces, you could make this logic a lot prettier\n        # but I kept it simple for the demo\n        name = None\n        if match[0]:\n            name = \"Lin-Manuel Miranda\"\n        elif match[1]:\n            name = \"Alex Lacamoire\"\n\n        face_names.append(name)\n\n    # Label the results\n    for (top, right, bottom, left), name in zip(face_locations, face_names):\n        if not name:\n            continue\n\n        # Draw a box around the face\n        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n\n        # Draw a label with a name below the face\n        cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n        font = cv2.FONT_HERSHEY_DUPLEX\n        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n\n    # Write the resulting image to the output video file\n    print(\"Writing frame {} / {}\".format(frame_number, length))\n    output_movie.write(frame)\n\n# All done!\ninput_movie.release()\ncv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2022-08-14T00:16:52.026559Z","iopub.execute_input":"2022-08-14T00:16:52.026989Z","iopub.status.idle":"2022-08-14T00:23:04.185573Z","shell.execute_reply.started":"2022-08-14T00:16:52.026953Z","shell.execute_reply":"2022-08-14T00:23:04.184480Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}